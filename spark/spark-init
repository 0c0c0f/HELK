#!/bin/bash
# Init script for spark
# Maintained by Roberto Rodriguez @Cyb3rWard0g
# Reference:
# https://github.com/elastic/logstash/blob/master/distribution/rpm/src/main/packaging/init.d/logstash
# https://github.com/spujadas/elk-docker/blob/master/logstash-init

### BEGIN INIT INFO
# Provides:  spark
# Required-Start:
# Required-Stop:
# Default-Start: 2 3 4 5
# Default-Stop: 0 1 6
# Short-Description: spark service
### END INIT INFO

PATH=/bin:/usr/bin:/sbin:/usr/sbin:/usr/local/bin
NAME=spark
DEFAULT=/etc/default/$NAME
export PATH

if [ $(id -u) -ne 0 ]; then
   echo "You need root privileges to run this script"
   exit 1
fi

# Source function library.
. /lib/lsb/init-functions

if [ -r /etc/default/rcS ]; then
  . /etc/default/rcS
fi

SPARK_HOME=/opt/helk/spark/spark-2.2.1-bin-hadoop2.7
SPARK_CONSOLE_PYSPARK_LOG=/var/log/spark/spark_pyspark.log
SPARK_EXEC=$SPARK_HOME/bin/pyspark
SPARK_CONFIG="2>&1 >> $SPARK_CONSOLE_PYSPARK_LOG 2>&1"
SPARK_USER=root
SPARK_GROUP=root
SPARK_NICE=""
SERVICE_NAME="spark"
SERVICE_DESCRIPTION="spark"
SPARK_PIDFILE=/var/run/spark.pid

# End of variables that can be overwritten in $DEFAULT

# overwrite settings from default file
if [ -f "$DEFAULT" ]; then
	. "$DEFAULT"
fi

# Adding SPARK location
export SPARK_HOME=/opt/helk/spark/spark-2.2.1-bin-hadoop2.7
export PATH=$SPARK_HOME/bin:$PATH

# Adding Jupyter Notebook Integration
export PYSPARK_DRIVER_PYTHON=/usr/local/bin/jupyter
export PYSPARK_DRIVER_PYTHON_OPTS="notebook --NotebookApp.open_browser=False --NotebookApp.ip='*' --NotebookApp.port=8880 --allow-root"
export PYSPARK_PYTHON=/usr/bin/python

[ -z "$SPARK_NICE" ] && SPARK_NICE=0

if [ ! -x "$SPARK_EXEC" ]; then
	echo "The spark startup script does not exists or it is not executable, tried: $SPARK_EXEC"
	exit 1
fi

start() {
	echo "Starting $NAME"

	if [ -n "$SPARK_PIDFILE" ] && [ ! -e "$SPARK_PIDFILE" ]; then
		touch "$SPARK_PIDFILE" && chown $SPARK_USER:$SPARK_GROUP "$SPARK_PIDFILE"
	fi

	# Start Service
	nice -n$SPARK_NICE chroot --userspec $SPARK_USER:$SPARK_GROUP / sh -c "
        cd /opt/helk
        exec $SPARK_EXEC $SPARK_CONFIG
    " &

  # Generate the pidfile from here. If we instead made the forked process
  # generate it there will be a race condition between the pidfile writing
  # and a process possibly asking for status.
  echo $! > $SPARK_PIDFILE

  echo "$NAME started."
  return 0
}

stop() {
  # Try a few times to kill TERM the program
  if status; then
    pid=$(cat "$SPARK_PIDFILE")
    echo "Killing $NAME (pid $pid) with SIGTERM"
    kill -TERM $pid
    # Wait for it to exit.
    for i in 1 2 3 4 5; do
      echo "Waiting for $NAME (pid $pid) to die..."
      status || break
      sleep 1
    done
    if status; then
      echo "$NAME stop failed; still running."
    else
      echo "$NAME stopped."
      rm -f $SPARK_PIDFILE
    fi
  fi
}

status() {
  if [ -f "$SPARK_PIDFILE" ] ; then
    pid=$(cat "$SPARK_PIDFILE")
    if kill -0 $pid > /dev/null 2> /dev/null; then
      # process by this pid is running.
      # It may not be our pid, but that's what you get with just pidfiles.
      # TODO(sissel): Check if this process seems to be the same as the one we
      # expect. It'd be nice to use flock here, but flock uses fork, not exec,
      # so it makes it quite awkward to use in this case.
      return 0
    else
      return 2 # program is dead but pid file exists
    fi
  else
    return 3 # program is not running
  fi
}

force_stop() {
  if status; then
    stop
    status && kill -KILL $(cat "$SPARK_PIDFILE")
    rm -f $SPARK_PIDFILE
  fi
}

case "$1" in
  start)
    status
    code=$?
    if [ $code -eq 0 ]; then
      echo "$NAME is already running"
    else
      start
      code=$?
    fi
    exit $code
    ;;

  stop) stop ;;

  force-stop) force_stop ;;

  status)
    status
    code=$?
    if [ $code -eq 0 ]; then
      echo "$NAME is running"
    else
      echo "$NAME is not running"
    fi
    exit $code
    ;;

  restart) stop && start ;;

  *)
    echo "Usage: $SCRIPTNAME {start|stop|force-stop|status|restart}" >&2
    exit 3
    ;;
esac

exit $?
